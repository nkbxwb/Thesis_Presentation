Automatically generated by Mendeley Desktop 1.15
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{Morris1998,
author = {Morris, David and Kearsley, John and Williams, Chris},
pages = {321},
title = {{Cancer: A Comprehensive Clinical Guide}},
year = {1998}
}
@book{Cooper1992,
address = {Boston},
author = {Cooper, Geoffrey},
pages = {354},
publisher = {Jones and Bartlett Learning},
title = {{Elements of Human Cancer}},
year = {1992}
}
@article{Wood2005,
abstract = {BACKGROUND: Longitudinal studies almost always have some individuals with missing outcomes. Inappropriate handling of the missing data in the analysis can result in misleading conclusions. Here we review a wide range of methods to handle missing outcomes in single and repeated measures data and discuss which methods are most appropriate. METHODS: Using data from a randomized controlled trial to compare two interventions for increasing physical activity, we compare complete-case analysis; ad hoc imputation techniques such as last observation carried forward and worst-case; model-based imputation; longitudinal models with random effects; and recently proposed joint models for repeated measures data and non-ignorable dropout. RESULTS: Estimated intervention effects from ad hoc imputation methods vary widely. Standard multiple imputation and longitudinal modelling agree closely, as they should. Modifying the modelling method to allow for non-ignorable dropout had little effect on estimated intervention effects, but imputing using a common imputation model in both groups gave more conservative results. CONCLUSIONS: Results from ad hoc imputation methods should be avoided in favour of methods with more plausible assumptions although they may be computationally more complex. Although standard multiple imputation methods and longitudinal modelling methods are equivalent for estimating the treatment effect, the two approaches suggest different ways of relaxing the assumptions, and the choice between them depends on contextual knowledge.},
author = {Wood, Angela M. and White, Ian and Hillsdon, Melvyn and Carpenter, James},
doi = {10.1093/ije/dyh297},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Wood et al. - Comparison of imputation and modelling methods in the analysis of a physical activity trial with missing outcomes - 2005.pdf:pdf},
isbn = {03005771},
issn = {03005771},
journal = {International Journal of Epidemiology},
keywords = {Dropout,Imputation,Last observation carried forward,Longitudinal data,Missing data,Non-ignorable,Random effects},
number = {1},
pages = {89--99},
pmid = {15333619},
title = {{Comparison of imputation and modelling methods in the analysis of a physical activity trial with missing outcomes}},
volume = {34},
year = {2005}
}
@book{Therneau2002a,
abstract = {This is a book for statistical practitioners, particularly those who design and analyze studies for survival and event history data. Its goal is to extend the toolkit beyond the basic triad provided by most statistical packages: the Kaplan-Meier estimator, log-rank test, and Cox regression model.},
author = {Therneau, Terry and Grambsch, Patricia},
booktitle = {Technometrics},
doi = {10.1198/tech.2002.s656},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Therneau, Grambsch - Modeling Survival Data Extending the Cox Model - 2002.pdf:pdf},
isbn = {0387987843},
issn = {0040-1706},
number = {1},
pages = {85--86},
pmid = {43993527},
title = {{Modeling Survival Data: Extending the Cox Model}},
volume = {44},
year = {2002}
}
@article{Freedman2008a,
abstract = {Regressions can be weighted by propensity scores in order to reduce bias. However, weighting is likely to increase random error in the estimates, and to bias the estimated standard errors downward, even when selection mechanisms are well understood. Moreover, in some cases, weighting will increase the bias in estimated causal parameters. If investigators have a good causal model, it seems better just to fit the model without weights. If the causal model is improperly specified, there can be significant problems in retrieving the situation by weighting, although weighting may help under some circumstances.},
author = {Freedman, David a and Berk, Richard a},
doi = {10.1177/0193841X08317586},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Freedman, Berk - Weighting regressions by propensity scores. - 2008(2).pdf:pdf},
isbn = {0193-841X (Print)},
issn = {0193-841X},
journal = {Evaluation review},
keywords = {causation,experiments,models,observational studies,propensity scores,regression,selection},
number = {4},
pages = {392--409},
pmid = {18591709},
title = {{Weighting regressions by propensity scores.}},
volume = {32},
year = {2008}
}
@article{Busso2014,
abstract = {Fr�lich (2004) compares the finite sample properties of reweighting and matching estimators of average treatment effects and concludes that reweighting performs far worse than even the simplest matching estimator. We argue that this conclusion is unjustified. Neither approach dominates the other uniformly across data generating processes (DGPs). Expanding on Fr�lich's (2004) analysis, this paper analyzes empirical as well as hypothetical DGPs and also examines the effect of misspecification. We conclude that reweighting is competitive with the most effective matching estimators when overlap is good, but that matching may be more effective when overlap is sufficiently poor.},
author = {Busso, M and DiNardo, J and McCrary, J},
doi = {10.1162/REST},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Busso, DiNardo, McCrary - New Evidence on the Finite Sample Properties of Propensity Score Reweighting and Matching Estimators - 2014.pdf:pdf},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
keywords = {pq{\_}tech{\_}Nearest{\_}Neighbor},
number = {2004},
pages = {"Just Accepted" section},
title = {{New Evidence on the Finite Sample Properties of Propensity Score Reweighting and Matching Estimators}},
volume = {(not yet a},
year = {2014}
}
@article{Austin2011a,
abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.},
author = {Austin, Peter C.},
doi = {10.1080/00273171.2011.568786},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Austin - An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies. - 2011.pdf:pdf},
isbn = {0027-3171},
issn = {0027-3171},
journal = {Multivariate behavioral research},
number = {3},
pages = {399--424},
pmid = {21818162},
title = {{An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3144483{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {46},
year = {2011}
}
@article{Gheyas2009,
abstract = {The treatment of incomplete data is an important step in pre-processing data prior to later analysis. We propose a novel non-parametric multiple imputation algorithm for estimating missing value. The proposed algorithm is based on Generalized Regression Neural Networks. We compare the proposed algorithm against existing algorithms on forty-five real and synthetic datasets. The effectiveness of imputation algorithms is evaluated in classification problems. The performance of proposed algorithm appears to be superior to that of other algorithms.},
author = {Gheyas, Iffat a and Smith, Leslie S},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Gheyas, Smith - A novel nonparametric multiple imputation algorithm for estimating missing data - 2009.pdf:pdf},
isbn = {9789881821010},
journal = {Proceedings of the World Congress on Engineering},
keywords = {Missing values,imputation,multiple imputation,single imputation},
number = {0},
pages = {1--6},
title = {{A novel nonparametric multiple imputation algorithm for estimating missing data}},
volume = {II},
year = {2009}
}
@article{Gayat2012,
author = {Gayat, Etienne and Resche-Rigon, Matthieu and Mary, Jean-Yves and Porcher, Rapha{\"{e}}l},
doi = {10.1002/pst.537},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Gayat et al. - Propensity score applied to survival data analysis through proportional hazards models a Monte Carlo study - 2012.pdf:pdf},
issn = {15391604},
journal = {Pharmaceutical Statistics},
keywords = {bias,propensity score,simulation,survival,treatment effect},
number = {3},
pages = {222--229},
title = {{Propensity score applied to survival data analysis through proportional hazards models: a Monte Carlo study}},
url = {http://doi.wiley.com/10.1002/pst.537},
volume = {11},
year = {2012}
}
@article{Goetghebeur1990,
abstract = {We propose a modified log rank test for the analysis of competing risks survival data, when failure type is missing for some individuals. The proposed test reduces to a standard log rank test when all failure types are known. The test arises from a partial likelihood, constructed under semiparametric assumptions on the relationship between cause-specific hazards.},
author = {Goetghebeur, E and Ryan, Louise},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Goetghebeur, Ryan - A modified log rank test for competing risks with missing failure type - 1990.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
number = {1},
pages = {207--211},
title = {{A modified log rank test for competing risks with missing failure type}},
url = {http://biomet.oxfordjournals.org/content/77/1/207.short},
volume = {77},
year = {1990}
}
@article{Gelman1992,
author = {Gelman, A. and Rubin, D. B.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Gelman, Rubin - Inference from iterative simulation using multiple sequences - 1992.pdf:pdf},
journal = {Statistical Science},
number = {4},
pages = {457--511},
title = {{Inference from iterative simulation using multiple sequences}},
volume = {7},
year = {1992}
}
@article{VanBuuren2007,
abstract = {The goal of multiple imputation is to provide valid inferences for statistical estimates from incomplete data. To achieve that goal, imputed values should preserve the structure in the data, as well as the uncertainty about this structure, and include any knowledge about the process that generated the missing data. Two approaches for imputing multivariate data exist: joint modeling (JM) and fully conditional specification (FCS). JM is based on parametric statistical theory, and leads to imputation procedures whose statistical properties are known. JM is theoretically sound, but the joint model may lack flexibility needed to represent typical data features, potentially leading to bias. FCS is a semi-parametric and flexible alternative that specifies the multivariate model by a series of conditional models, one for each incomplete variable. FCS provides tremendous flexibility and is easy to apply, but its statistical properties are difficult to establish. Simulation work shows that FCS behaves very well in the cases studied. The present paper reviews and compares the approaches. JM and FCS were applied to pubertal development data of 3801 Dutch girls that had missing data on menarche (two categories), breast development (five categories) and pubic hair development (six stages). Imputations for these data were created under two models: a multivariate normal model with rounding and a conditionally specified discrete model. The JM approach introduced biases in the reference curves, whereas FCS did not. The paper concludes that FCS is a useful and easily applied flexible alternative to JM when no convenient and realistic joint distribution can be specified.},
author = {van Buuren, Stef},
doi = {10.1177/0962280206074463},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/van Buuren - Multiple imputation of discrete and continuous data by fully conditional specification. - 2007.pdf:pdf},
isbn = {0962-2802 (Print)$\backslash$r0962-2802 (Linking)},
issn = {0962-2802},
journal = {Statistical methods in medical research},
number = {3},
pages = {219--242},
pmid = {17621469},
title = {{Multiple imputation of discrete and continuous data by fully conditional specification.}},
volume = {16},
year = {2007}
}
@article{Vaughan2015a,
author = {Vaughan, Adam S and Kelley, Colleen F and Luisi, Nicole and del Rio, Carlos and Sullivan, Patrick S and Rosenberg, Eli S},
doi = {10.1186/s12874-015-0017-y},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Vaughan et al. - An application of propensity score weighting to quantify the causal effect of rectal sexually transmitted infections on.pdf:pdf},
issn = {1471-2288},
journal = {BMC Medical Research Methodology},
keywords = {STI,HIV,Propensity scores,Survival analysis,Men wh,asvaugh,correspondence,edu,emory,hiv,marginal structural models,men who have sex,propensity scores,sti,survival analysis,with men},
number = {1},
pages = {1--9},
title = {{An application of propensity score weighting to quantify the causal effect of rectal sexually transmitted infections on incident HIV among men who have sex with men}},
url = {http://www.biomedcentral.com/1471-2288/15/25},
volume = {15},
year = {2015}
}
@article{Schoenfeld1982,
author = {Schoenfeld, David},
doi = {Doi 10.2307/2335876},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Schoenfeld - Partial Residuals for the Proportional Hazards Regression-Model - 1982.pdf:pdf},
isbn = {0006-3444},
journal = {Biometrika},
number = {1},
pages = {239--241},
title = {{Partial Residuals for the Proportional Hazards Regression-Model}},
url = {<Go to ISI>://A1982NL69300029},
volume = {69},
year = {1982}
}
@article{Zhao2014,
author = {Zhao, Yue and Herring, Amy H and Zhou, Haibo and Ali, Mirza W and Koch, Gary G},
doi = {10.1080/10543406.2013.860769.A},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Zhao et al. - ANALYSES OF TIME-TO-EVENT DATA WITH POSSIBLY - 2014.pdf:pdf},
keywords = {multiple imputation,sensitivity analysis,time-to-event data},
number = {2},
pages = {229--253},
title = {{ANALYSES OF TIME-TO-EVENT DATA WITH POSSIBLY}},
volume = {24},
year = {2014}
}
@article{Lee2010a,
abstract = {Statistical analysis in epidemiologic studies is often hindered by missing data, and multiple imputation is increasingly being used to handle this problem. In a simulation study, the authors compared 2 methods for imputation that are widely available in standard software: fully conditional specification (FCS) or "chained equations" and multivariate normal imputation (MVNI). The authors created data sets of 1,000 observations to simulate a cohort study, and missing data were induced under 3 missing-data mechanisms. Imputations were performed using FCS (Royston's "ice") and MVNI (Schafer's NORM) in Stata (Stata Corporation, College Station, Texas), with transformations or prediction matching being used to manage nonnormality in the continuous variables. Inferences for a set of regression parameters were compared between these approaches and a complete-case analysis. As expected, both FCS and MVNI were generally less biased than complete-case analysis, and both produced similar results despite the presence of binary and ordinal variables that clearly did not follow a normal distribution. Ignoring skewness in a continuous covariate led to large biases and poor coverage for the corresponding regression parameter under both approaches, although inferences for other parameters were largely unaffected. These results provide reassurance that similar results can be expected from FCS and MVNI in a standard regression analysis involving variously scaled variables.},
author = {Lee, Katherine J. and Carlin, John B.},
doi = {10.1093/aje/kwp425},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Lee, Carlin - Multiple imputation for missing data Fully conditional specification versus multivariate normal imputation - 2010.pdf:pdf},
isbn = {1476-6256 (Electronic)$\backslash$n0002-9262 (Linking)},
issn = {00029262},
journal = {American Journal of Epidemiology},
keywords = {Data interpretation,Epidemiologic methods,Imputation,Incomplete data,Missing data,Simulations,Statistical},
number = {5},
pages = {624--632},
pmid = {20106935},
title = {{Multiple imputation for missing data: Fully conditional specification versus multivariate normal imputation}},
volume = {171},
year = {2010}
}
@article{Hill2004a,
annote = {http://stats.stackexchange.com/questions/140761/survival-analysis-multiply-impute-5-datasets-to-average-one-propensity-score-th},
author = {Hill, Jennifer},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Hill - REDUCING BIAS IN TREATMENT EFFECT ESTIMATION IN OBSERVATIONAL STUDIES SUFFERING FROM MISSING DATA - 2004.pdf:pdf},
number = {January},
title = {{REDUCING BIAS IN TREATMENT EFFECT ESTIMATION IN OBSERVATIONAL STUDIES SUFFERING FROM MISSING DATA}},
year = {2004}
}
@article{Olmos2015,
abstract = {Propensity score weighting is one of the techniques used in controlling for selection biases in nonexperimental studies. Propensity scores can be used as weights to account for selection assignment differences between treatment and comparison groups. One of the advantages of this approach is that all the individuals in the study can be used for the outcomes evaluation. In this paper, we demonstrate how to conduct propensity score weighting using R. The purpose is to provide a stepby- step guide to propensity score weighting implementation for practitioners. In addition to strengths, some limitations of propensity score weighting are discussed.},
author = {Olmos, a and Govindasamy, P.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Olmos, Govindasamy - A Practical Guide for Using Propensity Score Weighting in R - 2015.pdf:pdf},
journal = {Practical Assessment, Research {\&} Evaluation},
number = {13},
pages = {1--8},
title = {{A Practical Guide for Using Propensity Score Weighting in R}},
url = {http://pareonline.net/getvn.asp?v=20{\&}n=13},
volume = {20},
year = {2015}
}
@article{Rosenbaum1983,
annote = {Central Rubin paper about propensity score},
author = {Rosenbaum, Paul and Rubin, Donald},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Rosenbaum, Rubin - The Central Role of the Propensity Score in Observational Studies for Causal Effects - 1983.pdf:pdf},
number = {1},
pages = {41--55},
title = {{The Central Role of the Propensity Score in Observational Studies for Causal Effects}},
volume = {70},
year = {1983}
}
@article{cat2015,
author = {Tusell, Fernando},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Tusell - Package ‘ cat ’ - 2015.pdf:pdf},
journal = {CRAN},
pages = {23},
title = {{Package ‘ cat ’}},
year = {2015}
}
@book{Rubin1987,
author = {Rubin, D. B.},
booktitle = {Harvard University},
doi = {10.1002/9780470316696},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Rubin - Multiple Imputation for Nonresponse in Surveys - 1987.pdf:pdf},
isbn = {ISBN: 047108705X :; 9780471087052; Series ISSN: 0271-6232; LCCN: 86-28935},
number = {JOHN WILEY {\&} SONS},
pmid = {13660112},
title = {{Multiple Imputation for Nonresponse in Surveys}},
year = {1987}
}
@article{Royston2004a,
author = {Royston, Patrick},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Royston - Multiple imputation of missing values - 2004.pdf:pdf},
journal = {The Stata Journal},
keywords = {micombine,mijoin,misplit,missing at random,missing data,multiple imputation,multivariate imputation,mvis,regression modeling,st0067,uvis},
number = {3},
pages = {227--241},
title = {{Multiple imputation of missing values}},
year = {2004}
}
@article{Austin2011a,
author = {Austin, Peter C.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Austin - A Tutorial and Case Study in Propensity Score Analysis An Application to Estimating the Effect of In-Hospital Smoking Cessation.pdf:pdf},
isbn = {0027-3171 (Print)$\backslash$n0027-3171 (Linking)},
issn = {0027-3171},
journal = {Multivariate Behavioral Research},
number = {1},
pages = {119--151},
pmid = {22287812},
title = {{A Tutorial and Case Study in Propensity Score Analysis: An Application to Estimating the Effect of In-Hospital Smoking Cessation Counseling on Mortality}},
volume = {46},
year = {2011}
}
@article{Submitted,
author = {Submitted, A Thesis},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Submitted - Using multiple imputation , survival analysis , and propensity score analysis in cancer data with a large amount of missing.pdf:pdf},
title = {{Using multiple imputation , survival analysis , and propensity score analysis in cancer data with a large amount of missing data Requirements for the Degree Master of Arts Statistics}}
}
@book{VanBuuren2012,
abstract = {Missing data form a problem in every scientific discipline, yet the techniques required to handle them are complicated and often lacking. One of the great ideas in statistical science—multiple imputation—fills gaps in the data with plausible values, the uncertainty of which is coded in the data itself. It also solves other problems, many of which are missing data problems in disguise. Flexible Imputation of Missing Data is supported by many examples using real data taken from the author's vast experience of collaborative research, and presents a practical guide for handling missing data under the framework of multiple imputation. Furthermore, detailed guidance of implementation in R using the author’s package {\{}MICE{\}} is included throughout the book. Assuming familiarity with basic statistical concepts and multivariate methods, Flexible Imputation of Missing Data is intended for two audiences: (Bio)statisticians, epidemiologists, and methodologists in the social and health sciences Substantive researchers who do not call themselves statisticians, but who possess the necessary skills to understand the principles and to follow the recipes This graduate-tested book avoids mathematical and technical details as much as possible: formulas are accompanied by a verbal statement that explains the formula in layperson terms. Readers less concerned with the theoretical underpinnings will be able to pick up the general idea, and technical material is available for those who desire deeper understanding. The analyses can be replicated in R using a dedicated package developed by the author.},
author = {{Van Buuren}, Stef},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Van Buuren - Flexible Imputation of Missing Data - 2012.pdf:pdf},
isbn = {9781439868249},
keywords = {Computers / Mathematical {\&} Statistical Software,Mathematics / Probability {\&} Statistics / General,Science / Life Sciences / Biology},
title = {{Flexible Imputation of Missing Data}},
year = {2012}
}
@article{Honaker2015,
author = {Honaker, James and King, Gary and Blackwell, Matthew},
doi = {10.1.1.149.9611},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Honaker, King, Blackwell - AMELIA II A Program for Missing Data - 2011.pdf:pdf},
isbn = {1548-7660},
issn = {15487660},
journal = {Journal Of Statistical Software},
keywords = {bootstrap,missing data,multiple imputation,r},
number = {7},
pages = {1--54},
title = {{AMELIA II : A Program for Missing Data}},
url = {http://gking.harvard.edu/amelia/},
volume = {45},
year = {2011}
}
@article{Wang1998,
abstract = {We consider the asymptotic behaviour of various parametric multiple imputation procedures which include but are not restricted to the `proper' imputation procedures proposed by Rubin (1978). The asymptotic variance structure of the resulting estimators is provided. This result is used to compare the relative efficiencies of different imputation procedures. It also provides a basis to understand the behaviour of two Monte Carlo iterative estimators, stochastic EM (Celeux {\&} Diebolt, 1985; Wei {\&} Tanner, 1990) and simulated EM (Ruud, 1991). We further develop properties of these estimators when they stop at iteration K with imputation size m. An application to a measurement error problem is used to illustrate the results. CR - Copyright {\&}{\#}169; 1998 Biometrika Trust},
author = {Wang, Naisyin and Robins, James M},
doi = {10.2307/2337494},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Wang, Robins - Large-Sample Theory for Parametric Multiple Imputation Procedures - 1998.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
number = {4},
pages = {935--948},
pmid = {185},
title = {{Large-Sample Theory for Parametric Multiple Imputation Procedures}},
url = {http://www.jstor.org/stable/2337494},
volume = {85},
year = {1998}
}
@article{AZUR2011a,
annote = {Pretty basic overview of MICE.},
archivePrefix = {arXiv},
arxivId = {1106.4512},
author = {Azur, Melissa and Stuart, Elizabeth and Frangakis, Constantine and Leaf, Philip},
eprint = {1106.4512},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Azur et al. - Multiple imputation by chained equations what is it and how does it work - 2011.pdf:pdf},
isbn = {0022-006X (Print)$\backslash$n0022-006X (Linking)},
issn = {1557-0657},
journal = {International Journal of Methods in Psychiatric Research},
number = {1},
pages = {1--5},
pmid = {21516187},
title = {{Multiple imputation by chained equations: what is it and how does it work?}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79951999327{\&}partnerID=tZOtx3y1},
volume = {20},
year = {2011}
}
@article{Austin2014a,
author = {Austin, Peter C. and Schuster, T.},
doi = {10.1177/0962280213519716},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Austin, Schuster - The performance of different propensity score methods for estimating absolute effects of treatments on survival outco.pdf:pdf},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {inverse probability of treatment,monte carlo simulations,observational study,propensity score,survival analysis,time-to-event outcomes,weighting},
pages = {1--24},
title = {{The performance of different propensity score methods for estimating absolute effects of treatments on survival outcomes: A simulation study}},
url = {http://smm.sagepub.com/cgi/doi/10.1177/0962280213519716},
year = {2014}
}
@article{Crump2006,
author = {Crump, Richard K and Hotz, V Joseph and Imbens, Guido W and Crump, Richard},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Crump et al. - Technical Working Paper Series Moving the Goalposts Addressing Limited Overlap in the Estimation - 2006.pdf:pdf},
journal = {NATIONAL BUREAU OF ECONOMIC RESEARCH},
title = {{Technical Working Paper Series Moving the Goalposts : Addressing Limited Overlap in the Estimation}},
year = {2006}
}
@article{norm2015,
author = {Novo, Alvaro A and Schafer, Joseph L},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Novo, Schafer - Package ‘ norm ’ - 2015.pdf:pdf},
journal = {CRAN},
title = {{Package ‘ norm ’}},
year = {2015}
}
@article{Kenward2007a,
author = {Kenward, Michael and Carpenter, James},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Kenward, Carpenter - Multiple imputation current perspectives - 2007.pdf:pdf},
isbn = {0962-2802 (Print)$\backslash$r0962-2802 (Linking)},
journal = {Stat Methods Med Res},
keywords = {Models, Statistical},
number = {3},
pages = {199--218},
pmid = {17621468},
title = {{Multiple imputation: current perspectives}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17621468$\backslash$nhttp://smm.sagepub.com/content/16/3/199.full.pdf},
volume = {16},
year = {2007}
}
@article{Florian2015,
author = {Florian, Author and Meinfelder, Maintainer Florian},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Florian, Meinfelder - BaBooN Bayesian Bootstrap Predictive Mean Matching - Multiple and Single Imputation for Discrete Data - 2015.pdf:pdf},
title = {{BaBooN: Bayesian Bootstrap Predictive Mean Matching - Multiple and Single Imputation for Discrete Data}},
url = {http://cran.r-project.org/package=BaBooN},
year = {2015}
}
@article{DAgostino1998a,
annote = {http://stats.stackexchange.com/questions/140761/survival-analysis-multiply-impute-5-datasets-to-average-one-propensity-score-th},
author = {D'Agostino, Ralph B.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/D'Agostino - Propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group - 1998.pdf:pdf},
isbn = {0277-6715 (Print)$\backslash$r0277-6715 (Linking)},
issn = {02776715},
journal = {Statistics in Medicine},
number = {19},
pages = {2265--2281},
pmid = {9802183},
title = {{Propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group}},
volume = {17},
year = {1998}
}
@article{Hughes2014a,
abstract = {BACKGROUND: Chained equations imputation is widely used in medical research. It uses a set of conditional models, so is more flexible than joint modelling imputation for the imputation of different types of variables (e.g. binary, ordinal or unordered categorical). However, chained equations imputation does not correspond to drawing from a joint distribution when the conditional models are incompatible. Concurrently with our work, other authors have shown the equivalence of the two imputation methods in finite samples.$\backslash$n$\backslash$nMETHODS: Taking a different approach, we prove, in finite samples, sufficient conditions for chained equations and joint modelling to yield imputations from the same predictive distribution. Further, we apply this proof in four specific cases and conduct a simulation study which explores the consequences when the conditional models are compatible but the conditions otherwise are not satisfied.$\backslash$n$\backslash$nRESULTS: We provide an additional "non-informative margins" condition which, together with compatibility, is sufficient. We show that the non-informative margins condition is not satisfied, despite compatible conditional models, in a situation as simple as two continuous variables and one binary variable. Our simulation study demonstrates that as a consequence of this violation order effects can occur; that is, systematic differences depending upon the ordering of the variables in the chained equations algorithm. However, the order effects appear to be small, especially when associations between variables are weak.$\backslash$n$\backslash$nCONCLUSIONS: Since chained equations is typically used in medical research for datasets with different types of variables, researchers must be aware that order effects are likely to be ubiquitous, but our results suggest they may be small enough to be negligible.},
author = {Hughes, Rachael and White, Ian and Seaman, Shaun and Carpenter, James and Tilling, Kate and Sterne, Jonathan},
doi = {10.1186/1471-2288-14-28},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Hughes et al. - Joint modelling rationale for chained equations. - 2014.pdf:pdf},
isbn = {1471-2288},
issn = {1471-2288},
journal = {BMC medical research methodology},
keywords = {chained equations imputation,gibbs sampling,joint modelling imputation,multiple imputation,multivariate missing data},
pages = {28},
pmid = {24559129},
title = {{Joint modelling rationale for chained equations.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3936896{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2014}
}
@article{Pigott2001,
abstract = {This paper reviews methods for handling missing data in a research study. Many researchers use ad hoc methods such as complete case analysis, available case analysis (pairwise deletion), or single-value imputation. Though these methods are easily implemented, they require assumptions about the data that rarely hold in practice. Model-based methods such as maximum likelihood using the EM algorithm and multiple imputation hold more promise for dealing with difficulties caused by missing data. While model-based methods require specialized computer programs and assumptions about the nature of the missing data, these methods are appropriate for a wider range of situations than the more commonly used ad hoc methods. The paper provides an illustration of the methods using data from an intervention study designed to increase students? ability to control their asthma symptoms.$\backslash$nThis paper reviews methods for handling missing data in a research study. Many researchers use ad hoc methods such as complete case analysis, available case analysis (pairwise deletion), or single-value imputation. Though these methods are easily implemented, they require assumptions about the data that rarely hold in practice. Model-based methods such as maximum likelihood using the EM algorithm and multiple imputation hold more promise for dealing with difficulties caused by missing data. While model-based methods require specialized computer programs and assumptions about the nature of the missing data, these methods are appropriate for a wider range of situations than the more commonly used ad hoc methods. The paper provides an illustration of the methods using data from an intervention study designed to increase students? ability to control their asthma symptoms.},
author = {Pigott, Therese D.},
doi = {10.1076/edre.7.4.353.8937},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Pigott - A Review of Methods for Missing Data - 2001.pdf:pdf},
isbn = {1380-3611},
issn = {1380-3611},
journal = {Educational Research and Evaluation},
number = {4},
pages = {353--383},
title = {{A Review of Methods for Missing Data}},
url = {http://www.tandfonline.com/doi/abs/10.1076/edre.7.4.353.8937},
volume = {7},
year = {2001}
}
@article{Frolich2015,
author = {Frolich, Markus and Huber, Martin and Wiesenfarth, Manuel},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Frolich, Huber, Wiesenfarth - The Finite Sample Performance of Semi- and Nonparametric Estimators for Treatment Effects and Policy Evalu.pdf:pdf},
journal = {IZA Discussion Paper},
keywords = {policy evaluation,simulation,treatment effects},
number = {8756},
title = {{The Finite Sample Performance of Semi- and Nonparametric Estimators for Treatment Effects and Policy Evaluation}},
year = {2015}
}
@article{Tsiatis2002,
author = {Tsiatis, Anastasios a. and Davidian, Marie and McNeney, Brad},
doi = {10.1093/biomet/89.1.238},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Tsiatis, Davidian, McNeney - Multiple imputation methods for testing treatment differences in survival distributions with missing cause.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
number = {1},
pages = {238--244},
title = {{Multiple imputation methods for testing treatment differences in survival distributions with missing cause of failure}},
volume = {89},
year = {2002}
}
@article{Austin2014,
author = {Austin, Peter C.},
doi = {10.1002/sim.5984},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Austin - The use of propensity score methods with survival or time-to-event outcomes reporting measures of effect similar to those used.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {confounding,event history analysis,inverse probability of treatment,marginal effects,observational study,propensity score,propensity score matching,survival analysis,weighting},
number = {7},
pages = {1242--1258},
title = {{The use of propensity score methods with survival or time-to-event outcomes: reporting measures of effect similar to those used in randomized experiments}},
url = {http://doi.wiley.com/10.1002/sim.5984},
volume = {33},
year = {2014}
}
@article{Long2012,
author = {Long, Qi and Hsu, Chiu-Hsieh and Li, Yisheng},
doi = {10.5705/ss.2010.069},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Long, Hsu, Li - Doubly robust nonparametric multiple imputation for ignorable missing data - 2012.pdf:pdf},
isbn = {1017-0405 (Print)$\backslash$n1017-0405 (Linking)},
issn = {10170405},
journal = {Statistica Sinica},
keywords = {doubly robust,imputation,missing at random,multiple imputation,nearest neighbor,nonparametric,sensitivity analysis},
number = {1},
pages = {1--22},
pmid = {22347786},
title = {{Doubly robust nonparametric multiple imputation for ignorable missing data}},
volume = {22},
year = {2012}
}
@article{Brand2003,
abstract = {This paper outlines a strategy to validate multiple imputation methods. Rubin's criteria for proper multiple imputation are the point of departure. We describe a simulation method that yields insight into various aspects of bias and efficiency of the imputation process. We propose a new method for creating incomplete data under a general Missing At Random {\{}(MAR){\}} mechanism. Software implementing the validation strategy is available as a {\{}SAS/IML{\}} module. The method is applied to investigate the behavior of polytomous regression imputation for categorical data.},
author = {Brand, Jaap P L and {Van Buuren}, Stef and Groothuis-Oudshoorn, Karin and Gelsema, Edzard S.},
doi = {10.1111/1467-9574.00219},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Brand et al. - A toolkit in SAS for the evaluation of multiple imputation methods - 2003.pdf:pdf},
issn = {00390402},
journal = {Statistica Neerlandica},
keywords = {Missing data mechanism,Multiple imputation,Proper imputation,Simulation},
number = {1},
pages = {36--45},
pmid = {38},
title = {{A toolkit in SAS for the evaluation of multiple imputation methods}},
volume = {57},
year = {2003}
}
@article{Zhu2015,
author = {Zhu, Hong and Lu, Bo},
doi = {10.1016/j.csda.2015.01.001},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Zhu, Lu - Multiple comparisons for survival data with propensity score adjustment - 2015.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
pages = {42--51},
title = {{Multiple comparisons for survival data with propensity score adjustment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947315000110},
volume = {86},
year = {2015}
}
@article{Liu2014a,
abstract = {Iterative imputation, in which variables are imputed one at a time each given a model predicting from all the others, is a popular technique that can be convenient and flexible, as it replaces a potentially difficult multivariate modeling problem with relatively simple univariate regressions. In this paper, we begin to characterize the stationary distributions of iterative imputations and their statistical properties. More precisely, when the conditional models are compatible (defined in the text), we give a set of sufficient conditions under which the imputation distribution converges in total variation to the posterior distribution of a Bayesian model. When the conditional models are incompatible but are valid, we show that the combined imputation estimator is consistent.},
archivePrefix = {arXiv},
arxivId = {1012.2902},
author = {Liu, Jingchen and Gelman, Andrew and Hill, Jennifer and Su, Yu-Sung and Kropko, Jonathan},
doi = {10.1093/biomet/ast044},
eprint = {1012.2902},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Liu et al. - On the stationary distribution of iterative imputations - 2014.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Chained equation,Convergence,Iterative imputation,Markov chain},
number = {1},
pages = {155--173},
title = {{On the stationary distribution of iterative imputations}},
volume = {101},
year = {2014}
}
@article{Stuart2009a,
abstract = {Multiple imputation is an effective method for dealing with missing data, and it is becoming increasingly common in many fields. However, the method is still relatively rarely used in epidemiology, perhaps in part because relatively few studies have looked at practical questions about how to implement multiple imputation in large data sets used for diverse purposes. This paper addresses this gap by focusing on the practicalities and diagnostics for multiple imputation in large data sets. It primarily discusses the method of multiple imputation by chained equations, which iterates through the data, imputing one variable at a time conditional on the others. Illustrative data were derived from 9,186 youths participating in the national evaluation of the Community Mental Health Services for Children and Their Families Program, a US federally funded program designed to develop and enhance community-based systems of care to meet the needs of children with serious emotional disturbances and their families. Multiple imputation was used to ensure that data analysis samples reflect the full population of youth participating in this program. This case study provides an illustration to assist researchers in implementing multiple imputation in their own data.},
author = {Stuart, Elizabeth and Azur, Melissa and Frangakis, Constantine and Leaf, Philip},
doi = {10.1093/aje/kwp026},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Stuart et al. - Multiple imputation with large data sets A case study of the children's mental health initiative - 2009.pdf:pdf},
isbn = {1476-6256 (Electronic)$\backslash$n0002-9262 (Linking)},
issn = {00029262},
journal = {American Journal of Epidemiology},
keywords = {Mental health services,Missing at random,Missing data,Multiple imputation},
number = {9},
pages = {1133--1139},
pmid = {19318618},
title = {{Multiple imputation with large data sets: A case study of the children's mental health initiative}},
volume = {169},
year = {2009}
}
@misc{Guo2010,
abstract = {Propensity score analysis is a relatively new and innovative class of statical methods that has proven useful treatment effects when using nonexperimental or observational data. Specifically; propensity score analysis offers an approach to program evaluation when randomized clinical trials are infeasible or unethical, or when researchers need to assess treatment effects from survey data, census data, administrative data, or other types of data " collected though the observations of systems as they operate in normal practice without any interventions implemnted by randomized assignment rules" (Rubin, 1997, p.757)},
author = {Guo, Shenyang and Fraser, Mark W.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Guo, Fraser - Propensity score analysis. Statistical methods and application - 2010.pdf:pdf},
isbn = {978-1-4129-5356-6},
keywords = {Social Scienses,observational data,propensity score,randomized},
pages = {370},
title = {{Propensity score analysis. Statistical methods and application}},
year = {2010}
}
@book{LittleRJAandRublin1987a,
author = {Little, Roderick and Rubin, Donald},
booktitle = {Wiley, New York.},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Little, Rubin - Statistical Analysis with Missing Data - 1987.pdf:pdf},
isbn = {3175723993},
title = {{Statistical Analysis with Missing Data}},
year = {1987}
}
@book{Enders2010,
address = {New York},
author = {Enders, Craig K.},
booktitle = {Guilford Press},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Enders - Applied Missing Data Analysis - 2010.pdf:pdf},
isbn = {9781606236390},
pages = {401},
title = {{Applied Missing Data Analysis}},
year = {2010}
}
@article{VanBuuren2011,
abstract = {The R package mice imputes incomplete multivariate data by chained equations. The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. mice 1.0 introduced predictor selection, passive imputation and automatic pooling. This article documents mice 2.9, which extends the functionality of mice 1.0 in several ways. In mice 2.9, the analysis of imputed data is made completely general, whereas the range ofmodels under which pooling works is substantially extended. mice 2.9 adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs. Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. mice 2.9 can be downloaded from the Comprehensive R Archive Network. This article provides a hands-on, stepwise approach to solve applied incomplete data problems.},
author = {{Van Buuren}, Stef and Groothuis-Oudshoorn, Karin},
doi = {10.1177/0962280206074463},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Van Buuren, Groothuis-Oudshoorn - mice Multivariate Imputation by Chained Equations in R - 2011.pdf:pdf},
isbn = {9067436771},
issn = {15487660},
journal = {Journal Of Statistical Software},
keywords = {chained equations,fully conditional specification,gibbs sampler,mice,multiple imputation,passive imputation,predictor selection,r},
number = {3},
pages = {1--67},
pmid = {22289957},
title = {{mice: Multivariate Imputation by Chained Equations in R}},
url = {http://igitur-archive.library.uu.nl/fss/2010-0608-200146/UUindex.html},
volume = {45},
year = {2011}
}
@book{Pintilie2006a,
abstract = {SMDFDFSDFS},
author = {Pintilie, Melania},
doi = {10.1002/9780470870709},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Pintilie - Competing Risks-A Practical Perspective - 2006.pdf:pdf},
isbn = {9780470870709},
title = {{Competing Risks-A Practical Perspective}},
url = {http://doi.wiley.com/10.1002/9780470870709},
year = {2006}
}
@article{Brookhart2008,
annote = {{\&}quot;The results suggest that variables that are unrelated to the exposure but related to the outcome should always be included in a PS model. The{\&}quot;},
author = {Brookhart, M. Alan and Schneeweiss, Sebastian and Rothman, Kenneth J. and Glynn, Robert J. and Avorn, Jerry and Til, St{\"{u}}rmer},
doi = {10.1016/j.drugalcdep.2008.02.002.A},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Brookhart et al. - Variable selection for propensity score models - 2008.pdf:pdf},
issn = {08966273},
keywords = {confounding,propensity scores,simulation,stepwise regression,subset selection,variable selection},
number = {10},
pages = {1203--1214},
title = {{Variable selection for propensity score models}},
volume = {15},
year = {2008}
}
@article{Marshall2009,
author = {Marshall, Andrea and Altman, Douglas G and Holder, Roger L and Royston, Patrick},
doi = {10.1186/1471-2288-9-57},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Marshall et al. - Combining estimates of interest in prognostic modelling studies after multiple imputation current practice and guideli.pdf:pdf},
isbn = {1471-2288 (Electronic)$\backslash$r1471-2288 (Linking)},
issn = {1471-2288},
journal = {BMC medical research methodology},
pages = {57},
pmid = {19638200},
title = {{Combining estimates of interest in prognostic modelling studies after multiple imputation: current practice and guidelines.}},
volume = {9},
year = {2009}
}
@article{Mitra2012,
abstract = {In many observational studies, analysts estimate treatment effects using propensity scores, e.g. by matching or sub-classifying on the scores. When some values of the covariates are missing, analysts can use multiple imputation to fill in the missing data, estimate propensity scores based on the m completed datasets, and use the propensity scores to estimate treatment effects. We compare two approaches to implement this process. In the first, the analyst estimates the treatment effect using propensity score matching within each completed data set, and averages the m treatment effect estimates. In the second approach, the analyst averages the m propensity scores for each record across the completed datasets, and performs propensity score matching with these averaged scores to estimate the treatment effect. We compare properties of both methods via simulation studies using artificial and real data. The simulations suggest that the second method has greater potential to produce substantial bias reductions than the first, particularly when the missing values are predictive of treatment assignment.},
annote = {I did a google search for this

I am going to need to write out what is happening to make sense of it},
author = {Mitra, R. and Reiter, J. P.},
doi = {10.1177/0962280212445945},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Mitra, Reiter - A comparison of two methods of estimating propensity scores after multiple imputation - 2012.pdf:pdf},
issn = {0962-2802},
journal = {Statistical Methods in Medical Research},
keywords = {missing data,multiple imputation,observational studies,propensity score},
pages = {1--17},
pmid = {22687877},
title = {{A comparison of two methods of estimating propensity scores after multiple imputation}},
year = {2012}
}
@article{King2015,
abstract = {Working paper},
author = {King, Gary and Nielsen, Richard},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/King, Nielsen - Why Propensity Scores Should Not Be Used for Matching - 2015.pdf:pdf},
journal = {Working paper},
title = {{Why Propensity Scores Should Not Be Used for Matching}},
year = {2015}
}
@article{Su2011,
abstract = {Our mi package in R has several features that allow the user to get inside the imputation process and evaluate the reasonableness of the resulting models and imputations. These features include: exible choice of predictors, models, and transformations for chained imputation models; binned residual plots for checking the fit of the conditional distributions used for imputation; and plots for comparing the distributions of observed and imputed data in one and two dimensions. In addition, we use Bayesian models and weakly informative prior distributions to construct more stable estimates of imputation models. Our goal is to have a demonstration package that (a) avoids many of the practical problems that arise with existing multivariate imputation programs, and (b) demonstrates state-of-the-art diagnostics that can be applied more generally and can be incorporated into the software of the others.},
author = {Su, Yu-Sung and Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Su et al. - Multiple Imputation with Diagnostics (mi) in R Opening Windows into the Black Box - 2011.pdf:pdf},
isbn = {1548-7660},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {R,chained eq,chained equations,mi,model diagnostics,multiple imputation,weakly informative,weakly informative prior},
number = {2},
pages = {1--31},
title = {{Multiple Imputation with Diagnostics (mi) in R: Opening Windows into the Black Box}},
volume = {45},
year = {2011}
}
@article{White2011a,
abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
author = {White, Ian and Royston, Patrick and Wood, Angela M.},
doi = {10.1002/sim.4067},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/White, Royston, Wood - Multiple imputation using chained equations Issues and guidance for practice - 2011.pdf:pdf},
isbn = {1097-0258 (Electronic)$\backslash$n0277-6715 (Linking)},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Fully conditional specification,Missing data,Multiple imputation},
number = {4},
pages = {377--399},
pmid = {21225900},
title = {{Multiple imputation using chained equations: Issues and guidance for practice}},
volume = {30},
year = {2011}
}
@article{Kaplan1958,
abstract = {In lifetesting, medical follow-up, and other fields the observation of the time of occurrence of the event of interest (called a death) may be prevented for some of the items of the sample by the previous occur- rence of some other event (called a loss). Losses may be either accidental or controlled, the latter resulting from a decision to terminate certain observations. In either case it is usually assumed in this paper that the lifetime (age at death) is independent of the potential loss time; in practice this assumption deserves careful scrutiny. Despite the resulting incompleteness of the data, it is desired to estimate the proportion P(t) of items in the population whose lifetimes would exceed t (in the absence of such losses), without making any assumption about the form of the function P(t). The observation for each item of a suitable initial event, marking the beginning of its lifetime, is presupposed. For random samples of size N the product-limit (PL) estimate can be defined as follows: List and label the N observed lifetimes (whether to death or loss) in order of increasing magnitude, so that one has ? o <tjI <t.2' < . .<tN'. Then P(t) =11r [(N-r)/(N-r+1)], where r assumes those values for which tr'<t and for which tr/ measures the time to death. This estimate is the distribution, unrestricted as to form, which maximizes the likelihood of the observations. Other estimates that are discussed are the actuarial estimates (which are also products, but with the number of factors usually reduced by grouping); and reduced-sample (RS) estimates, which require that losses not be accidental, so that the limits of observation (potential loss times) are known even for those items whose deaths are observed. When no losses occur at ages less than t, the estimate of P(t) in all cases re- duces to the usual binomial estimate, namely, the observed proportion of survivors},
author = {Kaplan, E L and Meier, Paul},
doi = {10.2307/2281868},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Kaplan, Meier - Nonparametric Estimation from Incomplete Observations - 1958.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {282},
pages = {457--481},
pmid = {252},
title = {{Nonparametric Estimation from Incomplete Observations}},
volume = {53},
year = {1958}
}
@article{Lunceford2004,
abstract = {Estimation of treatment effects with causal interpretation from observational data is complicated because exposure to treatment may be confounded with subject characteristics. The propensity score, the probability of treatment exposure conditional on covariates, is the basis for two approaches to adjusting for confounding: methods based on stratification of observations by quantiles of estimated propensity scores and methods based on weighting observations by the inverse of estimated propensity scores. We review popular versions of these approaches and related methods offering improved precision, describe theoretical properties and highlight their implications for practice, and present extensive comparisons of performance that provide guidance for practical use.},
author = {Lunceford, Jared K. and Davidian, Marie},
doi = {10.1002/sim.1903},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Lunceford, Davidian - Stratification and weighting via the propensity score in estimation of causal treatment effects A comparative stud.pdf:pdf},
isbn = {0277-6715},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Covariate balance,Double robustness,Inverse-probability-of-treatment-weighted-estimato,Observational data},
number = {19},
pages = {2937--2960},
pmid = {15351954},
title = {{Stratification and weighting via the propensity score in estimation of causal treatment effects: A comparative study}},
volume = {23},
year = {2004}
}
@article{Gelman2001a,
author = {Gelman, Andrew and Raghunathan, Te},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Gelman, Raghunathan - Using conditional distributions for missing-data imputation - 2001.pdf:pdf},
journal = {Statistical Science},
pages = {268--269},
title = {{Using conditional distributions for missing-data imputation}},
volume = {15},
year = {2001}
}
@article{Dewanji1992,
abstract = {The modified log rank test for competing risks with missing failure type suggested by Goetghebeur {\&} Ryan (1990) is derived from a partial likelihood which leaves out some information. This extra information is incorporated to give a new partial likelihood and hence a new test statistic.},
author = {Dewanji, Anup},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Dewanji - A note on a test for competing risks with missing failure type - 1992.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
number = {4},
pages = {855--857},
title = {{A note on a test for competing risks with missing failure type}},
volume = {79},
year = {1992}
}
@article{Posner2012a,
annote = {This looks unfinished. Might want to look at 


Comparing Standard Regression, Propensity Score Matching, and Instrumental Variables Methods for Determining the Effectiveness of Mammography in Older Women.  Michael A. Posner, Arlene Ash, Michael Shwartz, Karen Freund, Mark Moskowitz. Health Services and Outcomes Research Methodology, 2001; 2:279-290.},
author = {Posner, Ma and Ash, Arlene},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Posner, Ash - Comparing weighting methods in propensity score analysis - 2012.pdf:pdf},
journal = {Unpublished working paper, Columbia {\ldots}},
title = {{Comparing weighting methods in propensity score analysis}},
url = {http://www.stat.columbia.edu/{~}gelman/stuff{\_}for{\_}blog/posner.pdf},
year = {2012}
}
@article{VanBuuren2006,
abstract = {The use of the Gibbs sampler with fully conditionally specified models, where the distribution of each variable given the other variables is the starting point, has become a popular method to create imputations in incomplete multivariate data. The theoretical weakness of this approach is that the specified conditional densities can be incompatible, and therefore the stationary distribution to which the Gibbs sampler attempts to converge may not exist. This study investigates practical consequences of this problem by means of simulation. Missing data are created under four different missing data mechanisms. Attention is given to the statistical behavior under compatible and incompatible models. The results indicate that multiple imputation produces essentially unbiased estimates with appropriate coverage in the simple cases investigated, even for the incompatible models. Of particular interest is that these results were produced using only five Gibbs iterations starting from a simple draw from observed marginal distributions. It thus appears that, despite the theoretical weaknesses, the actual performance of conditional model specification for multivariate imputation can be quite good, and therefore deserves further study.},
annote = {Simulation study that shows why compatability isn't really an issue},
author = {{Van Buuren}, Stef and Brand, J. P.L. and Groothuis-Oudshoorn, C. G.M. and Rubin, Donald},
doi = {10.1080/10629360600810434},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Van Buuren et al. - Fully conditional specification in multivariate imputation - 2006.pdf:pdf},
isbn = {0094-9655},
issn = {0094-9655},
journal = {Journal of Statistical Computation and Simulation},
number = {12},
pages = {1049--1064},
title = {{Fully conditional specification in multivariate imputation}},
volume = {76},
year = {2006}
}
@book{Kalbfleisch2002,
author = {Kalbfleisch, John and Prentice, Ross},
booktitle = {Technometrics},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Kalbfleisch, Prentice - The Statistical Analysis of Failure Time Data - 2002.pdf:pdf},
isbn = {9780471363576},
title = {{The Statistical Analysis of Failure Time Data}},
year = {2002}
}
@article{Barnard1999,
abstract = {An appealing feature of multiple imputation is the simplicity of the rules for combining the multiple complete-data inferences into a final inference, the repeated-imputation inference (Rubin, 1987). This inference is based on a t distribution and is derived from a Bayesian paradigm under the assumption that the complete-data degrees of freedom, v(com), are infinite, but the number of imputations, m, is finite. When v(com) is small and there is only a modest proportion of missing data, the calculated repeated-imputation degrees of freedom, v(m), for the t reference distribution can be much larger than v(com), which is clearly inappropriate. Following the Bayesian paradigm, we derive an adjusted degrees of freedom, (v) over tilde(m), with the following three properties: for fixed m and estimated fraction of missing information, (v) over tilde(m) monotonically increases in v(com); (v) over tilde(m) is always less than or equal to v(com); and (v) over tilde(m) equals v(m) when v(com) is infinite. A small simulation study demonstrates the superior frequentist performance when using (v) over tilde(m) rather than v(m).},
author = {Barnard, J and Rubin, D. B.},
doi = {DOI 10.1093/biomet/86.4.948},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Barnard, Rubin - Small-sample degrees of freedom with multiple imputation - 1999.pdf:pdf},
isbn = {0006-3444},
issn = {0006-3444},
journal = {Biometrika},
keywords = {bayesian inference,fraction of missing information,missing at random,missing data mechanism,repeated imputation},
number = {4},
pages = {948--955},
title = {{Small-sample degrees of freedom with multiple imputation}},
url = {<Go to ISI>://000084833000018},
volume = {86},
year = {1999}
}
@article{Morisot2015a,
author = {Morisot, Adeline and Bessaoud, Fa{\"{\i}}za and Landais, Paul and R{\'{e}}billard, Xavier and Tr{\'{e}}tarre, Brigitte and Daur{\`{e}}s, Jean-Pierre},
doi = {10.1186/s12874-015-0048-4},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Morisot et al. - Prostate cancer net survival and cause-specific survival rates after multiple imputation - 2015.pdf:pdf},
issn = {1471-2288},
journal = {BMC Medical Research Methodology},
keywords = {Multiple imputation,Net survival,Cause-specific su,cause-specific survival,erspc,multiple imputation,net survival},
number = {1},
pages = {54},
publisher = {BMC Medical Research Methodology},
title = {{Prostate cancer: net survival and cause-specific survival rates after multiple imputation}},
url = {http://www.biomedcentral.com/1471-2288/15/54},
volume = {15},
year = {2015}
}
@article{Cox1972,
abstract = {The abalysis of censored failure times is considered . assumed on each individual are available values of on or more explanatory variables. the hazard function is taken to be function of the explanatory variables and unknown function of time. a conditional likelihood is obtained lading to ibferense about the unknown regression coffcients.},
author = {Cox, D.R.},
doi = {10.2307/2985181},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Cox - Regression Models and Life-Tables - 1972.pdf:pdf},
isbn = {00359246},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
keywords = {AGE SPECIFIC RATE,CENSORED DATA,HAZARD FUNCTION,LIFE TABLE,PRODUCT LIMIT ESTIMATE,REGRESSION,RELAYABILITY,THEORY: ACCELERATED LIFE TEST,TWO SAMPLE RANK TEST: MEDICAL APPLICATION,asymptotic theory,conditional inference},
number = {2},
pages = {187--220},
pmid = {2985181},
title = {{Regression Models and Life-Tables}},
url = {http://links.jstor.org/sici?sici=0035-9246(1972)34:2<187:RMAL>2.0.CO;2-6$\backslash$nhttp://www.jstor.org},
volume = {34},
year = {1972}
}
@article{Li2013,
abstract = {<p>Propensity score (PS) matching is widely used for studying treatment effects in observational studies. This article proposes the method of matching weights (MWs) as an analog to one-to-one pair matching without replacement on the PS with a caliper. Compared with pair matching, the proposed method offers more efficient estimation, more accurate variance calculation, better balance, and simpler asymptotic analysis. A statistical test for the misspecification of the PS model is proposed for balance checking purposes. An augmented version of the MW estimator is developed that has the double robust property, that is, the estimator is consistent, if either the outcome model or the PS model is correct. The proposed method is studied in simulations and illustrated through a real data example.</p>},
author = {Li, Liang and Greene, Tom},
doi = {10.1515/ijb-2012-0030},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Li, Greene - A Weighting Analogue to Pair Matching in Propensity Score Analysis - 2013.pdf:pdf},
issn = {1557-4679},
journal = {The International Journal of Biostatistics},
keywords = {anderson cancer center,causal inference,corresponding author,department of biostatistics,division of epidemiology,double robust,e-mail,houston,inverse probability weighting,liang li,lli15,matching weight,mdanderson,mirror histogram,org,salt lake city,texas,tom greene,university of texas md,university of utah,usa,utah},
number = {2},
pages = {215--234},
title = {{A Weighting Analogue to Pair Matching in Propensity Score Analysis}},
url = {http://www.degruyter.com/view/j/ijb.2013.9.issue-2/ijb-2012-0030/ijb-2012-0030.xml},
volume = {9},
year = {2013}
}
@article{Reiter2008,
abstract = {Multiple imputation can handle missing data and disclosure limitation simultaneously. First, fill in the missing data to generate m completed datasets, then replace confidential values in each completed dataset with r imputations. I investigate how to select m and r.},
author = {Reiter, Jerome P},
doi = {10.1016/j.spl.2007.04.020},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Reiter - Selecting the number of imputed datasets when using multiple imputation for missing data and disclosure limitation - 2008.pdf:pdf},
issn = {0167-7152},
journal = {Statistics {\&} Probability Letters},
keywords = {Confidentiality,Disclosure,Missing data,Multiple imputation,Synthetic data},
number = {1},
pages = {15--20},
title = {{Selecting the number of imputed datasets when using multiple imputation for missing data and disclosure limitation}},
url = {http://www.sciencedirect.com/science/article/pii/S0167715207001654},
volume = {78},
year = {2008}
}
@book{Klein1984,
author = {Klein, John and Moeschberger, Melvin},
doi = {10.1145/390011.808243},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Klein, Moeschberger - Techniques for Censored and Truncated Data - 1984.pdf:pdf},
isbn = {038795399X},
issn = {03621340},
pages = {536},
title = {{Techniques for Censored and Truncated Data}},
year = {1984}
}
@article{Kropko2014,
abstract = {We consider the relative performance of two common approaches to multiple imputation (MI): joint MI, in which the data are modeled as a sample from a joint distribution; and conditional MI, in which each variable is modeled conditionally on all the others. Implementations of joint MI are typically restricted in two ways: first, the joint distribution of the data is assumed to be multivariate normal, and second, in order to use the multivariate normal distribution, categories of discrete variables are assumed to be probabilistically constructed from continuous values. We use simulations to examine the implications of these assumptions. For each approach, we assess (1) the accuracy of the imputed values, and (2) the accuracy of coefficients and fitted values from a model fit to completed datasets. These simulations consider continuous, binary, ordinal, and unordered-categorical variables. One set of simulations uses multivariate normal data and one set uses data from the 2008 American National Election Study. We implement a less restrictive approach than is typical when evaluating methods using simulations in the missing data literature: in each case, missing values are generated by carefully following the conditions necessary for missingness to be “missing at random” (MAR).We find that in these situations conditional MI is more accurate than joint multivariate normal MI whenever the data include categorical variables.},
annote = {We find that in these situations conditional MI is more accurate than joint MVN MI whenever the data include categorical variables.

In general, we see that there are two kinds of results. Either conditional MI outperforms jointMVN MI and the other competitors by a fair margin, or there is very little difference between joint MVN MI and conditional MI. In no case does joint MVN MI clearly outperform conditional MI.},
author = {Kropko, Jonathan and Goodrich, Ben and Gelman, Andrew and Hill, Jennifer},
doi = {10.1093/pan/mpu007},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Kropko et al. - Multiple Imputation for Continuous and Categorical Data Comparing Joint Multivariate Normal and Conditional Approache(2).pdf:pdf},
issn = {1047-1987},
journal = {Political Analysis},
pages = {497--519},
title = {{Multiple Imputation for Continuous and Categorical Data: Comparing Joint Multivariate Normal and Conditional Approaches}},
url = {http://pan.oxfordjournals.org/cgi/doi/10.1093/pan/mpu007},
year = {2014}
}
@article{Harder2011,
author = {Harder, Valerie S. and Stuart, Elizabeth A. and {James C. Anthony}},
doi = {10.1037/a0019623.Propensity},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Harder, Stuart, James C. Anthony - Propensity score techniques and the assessment of measured covariate balance to test causal associati.pdf:pdf},
journal = {Psychological Methods},
keywords = {computer-aided drug design,cyclophilin,free energy perturbation,hiv,reverse transcriptase},
number = {3},
pages = {234--249},
title = {{Propensity score techniques and the assessment of measured covariate balance to test causal associations in psychological research}},
volume = {15},
year = {2011}
}
@book{Angrist2008,
author = {Angrist, Jd and Pischke, Js},
file = {:C$\backslash$:/Users/Nathan/Documents/Mendeley Desktop/Angrist, Pischke - Mostly harmless econometrics An empiricist's companion - 2008.pdf:pdf},
isbn = {9781400829828},
issn = {0007666X},
number = {March},
pages = {274},
pmid = {15344040},
title = {{Mostly harmless econometrics: An empiricist's companion}},
year = {2008}
}
